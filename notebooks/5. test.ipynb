{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import scipy\n",
    "import torch\n",
    "import onnxruntime\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = Path().resolve()\n",
    "while not current_dir.name.endswith(\"xlm-roberta-base-cls-depression\"):\n",
    "    current_dir = current_dir.parent\n",
    "\n",
    "os.chdir(current_dir)\n",
    "\n",
    "input_test_data = current_dir / \"data/clean/test.csv\"\n",
    "input_pytorch_model_dir = current_dir / \"data/models/xlm-roberta-base-cls-depression\"\n",
    "input_model_dir = current_dir / \"data/dist/xlm-roberta-base-cls-depression\"\n",
    "input_model_base_filename = input_model_dir / \"model.onnx\"\n",
    "# input_model_quantized_filename = input_model_dir / \"model.opt.quant.onnx\" / \"model_quantized.onnx\"\n",
    "input_model_quantized_filename = input_model_dir / \"model.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pre process function take a question and a context, and generates the tensor inputs to the model:\n",
    "# - input_ids: the words in the question encoded as integers\n",
    "# - attention_mask: not used in this model\n",
    "# - token_type_ids: a list of 0s and 1s that distinguish between the words of the question and the words of the context\n",
    "# This function also returns the words contained in the question and the context, so that the answer can be decoded into a phrase.\n",
    "def preprocess(text):\n",
    "    encoded = tokenizer(\n",
    "        text, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\"\n",
    "    )\n",
    "    return (encoded[\"input_ids\"], encoded[\"attention_mask\"])\n",
    "\n",
    "\n",
    "# The post process function maps the list of start and end log probabilities onto a text answer, using the text tokens from the question\n",
    "# and context.\n",
    "def postprocess(tokens, start, end):\n",
    "    results = {}\n",
    "    answer_start = np.argmax(start)\n",
    "    answer_end = np.argmax(end)\n",
    "    if answer_end >= answer_start:\n",
    "        answer = tokens[answer_start]\n",
    "        for i in range(answer_start + 1, answer_end + 1):\n",
    "            if tokens[i][0:2] == \"##\":\n",
    "                answer += tokens[i][2:]\n",
    "            else:\n",
    "                answer += \" \" + tokens[i]\n",
    "        results[\"answer\"] = answer.capitalize()\n",
    "    else:\n",
    "        results[\"error\"] = (\n",
    "            \"I am unable to find the answer to this question. Can you please ask another question?\"\n",
    "        )\n",
    "    return results\n",
    "\n",
    "\n",
    "# Perform the one-off initialization for the prediction. The init code is run once when the endpoint is setup.\n",
    "def init_models():\n",
    "    global tokenizer, session, model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(input_pytorch_model_dir)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
    "    session = onnxruntime.InferenceSession(\n",
    "        str(input_model_quantized_filename), providers=[\"CPUExecutionProvider\"]\n",
    "    )\n",
    "\n",
    "# Run the PyTorch model, for functional and performance comparison\n",
    "def run_pytorch(raw_data):\n",
    "    inputs = json.loads(raw_data)\n",
    "    input_ids, attention_mask = preprocess(inputs[\"text\"])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    prediction = torch.argmax(probabilities, dim=1).item()\n",
    "    return {\n",
    "        \"prediction\": prediction,\n",
    "        \"probability\": probabilities[0][prediction].item(),\n",
    "    }\n",
    "\n",
    "\n",
    "# Run the ONNX model with ONNX Runtime\n",
    "def run_onnx(raw_data):\n",
    "    inputs = json.loads(raw_data)\n",
    "    input_ids, attention_mask = preprocess(inputs[\"text\"])\n",
    "    model_inputs = {\n",
    "        \"input_ids\": np.asarray(input_ids, dtype=np.int64),\n",
    "        \"attention_mask\": np.asarray(attention_mask, dtype=np.int64)\n",
    "        }\n",
    "    outputs = session.run([\"logits\"], model_inputs)\n",
    "    logits = outputs[0]\n",
    "    probabilities = scipy.special.softmax(logits, axis=1)\n",
    "    prediction = np.argmax(probabilities, axis=1)[0]\n",
    "    return {\n",
    "        \"prediction\": prediction,\n",
    "        \"probability\": probabilities[0][prediction].item(),\n",
    "    }\n",
    "\n",
    "init_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing texts: 100%|██████████| 4892/4892 [17:24<00:00,  4.69it/s]\n",
      "C:\\Users\\Alexander\\AppData\\Local\\Temp\\ipykernel_76304\\3763632933.py:116: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot([self.results['pytorch']['times'], self.results['onnx']['times']],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison Report\n",
      "=====================\n",
      "\n",
      "PYTORCH Model Metrics:\n",
      "====================\n",
      "Accuracy: 0.9867\n",
      "Precision: 0.9799\n",
      "Recall: 0.9827\n",
      "F1 Score: 0.9813\n",
      "ROC-AUC Score: 0.0927\n",
      "Average Inference Time: 145.66 ms\n",
      "Inference Time Std: 2.81 ms\n",
      "\n",
      "ONNX Model Metrics:\n",
      "====================\n",
      "Accuracy: 0.9871\n",
      "Precision: 0.9811\n",
      "Recall: 0.9827\n",
      "F1 Score: 0.9819\n",
      "ROC-AUC Score: 0.0679\n",
      "Average Inference Time: 66.88 ms\n",
      "Inference Time Std: 1.92 ms\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ModelComparison:\n",
    "    def __init__(self, run_pytorch, run_onnx):\n",
    "        \"\"\"\n",
    "        Initialize the comparison class with model inference functions.\n",
    "        \n",
    "        Args:\n",
    "            run_pytorch: Function that takes text input and returns dict with prediction and probability\n",
    "            run_onnx: Function that takes text input and returns dict with prediction and probability\n",
    "        \"\"\"\n",
    "        self.run_pytorch = run_pytorch\n",
    "        self.run_onnx = run_onnx\n",
    "        self.results = {\n",
    "            'pytorch': {'predictions': [], 'probabilities': [], 'times': []},\n",
    "            'onnx': {'predictions': [], 'probabilities': [], 'times': []}\n",
    "        }\n",
    "        \n",
    "    def process_batch(self, texts: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Process a batch of texts through both models.\n",
    "        \n",
    "        Args:\n",
    "            texts: List of input texts to process\n",
    "        \"\"\"\n",
    "        for text in tqdm(texts, desc=\"Processing texts\"):\n",
    "            input_json = json.dumps({\"text\": text})\n",
    "            \n",
    "            # PyTorch inference\n",
    "            start_time = time.time()\n",
    "            pytorch_result = self.run_pytorch(input_json)\n",
    "            pytorch_time = time.time() - start_time\n",
    "            \n",
    "            # ONNX inference\n",
    "            start_time = time.time()\n",
    "            onnx_result = self.run_onnx(input_json)\n",
    "            onnx_time = time.time() - start_time\n",
    "            \n",
    "            # Store results\n",
    "            self.results['pytorch']['predictions'].append(pytorch_result['prediction'])\n",
    "            self.results['pytorch']['probabilities'].append(pytorch_result['probability'])\n",
    "            self.results['pytorch']['times'].append(pytorch_time)\n",
    "            \n",
    "            self.results['onnx']['predictions'].append(onnx_result['prediction'])\n",
    "            self.results['onnx']['probabilities'].append(onnx_result['probability'])\n",
    "            self.results['onnx']['times'].append(onnx_time)\n",
    "    \n",
    "    def calculate_metrics(self, true_labels: List[int]) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate various classification metrics for both models.\n",
    "        \n",
    "        Args:\n",
    "            true_labels: List of ground truth labels\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing metrics for both models\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        for model_name in ['pytorch', 'onnx']:\n",
    "            predictions = self.results[model_name]['predictions']\n",
    "            probabilities = self.results[model_name]['probabilities']\n",
    "            \n",
    "            metrics[model_name] = {\n",
    "                'accuracy': accuracy_score(true_labels, predictions),\n",
    "                'precision': precision_score(true_labels, predictions),\n",
    "                'recall': recall_score(true_labels, predictions),\n",
    "                'f1': f1_score(true_labels, predictions),\n",
    "                'roc_auc': roc_auc_score(true_labels, probabilities),\n",
    "                'confusion_matrix': confusion_matrix(true_labels, predictions),\n",
    "                'avg_inference_time': np.mean(self.results[model_name]['times']),\n",
    "                'std_inference_time': np.std(self.results[model_name]['times'])\n",
    "            }\n",
    "            \n",
    "        return metrics\n",
    "    \n",
    "    def plot_confusion_matrices(self, metrics: Dict) -> None:\n",
    "        \"\"\"\n",
    "        Plot confusion matrices for both models side by side.\n",
    "        \n",
    "        Args:\n",
    "            metrics: Dictionary containing metrics including confusion matrices\n",
    "        \"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Plot PyTorch confusion matrix\n",
    "        sns.heatmap(metrics['pytorch']['confusion_matrix'], annot=True, fmt='d', ax=ax1)\n",
    "        ax1.set_title('PyTorch Model Confusion Matrix')\n",
    "        ax1.set_xlabel('Predicted')\n",
    "        ax1.set_ylabel('True')\n",
    "        \n",
    "        # Plot ONNX confusion matrix\n",
    "        sns.heatmap(metrics['onnx']['confusion_matrix'], annot=True, fmt='d', ax=ax2)\n",
    "        ax2.set_title('ONNX Model Confusion Matrix')\n",
    "        ax2.set_xlabel('Predicted')\n",
    "        ax2.set_ylabel('True')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('confusion_matrices.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_inference_times(self) -> None:\n",
    "        \"\"\"Plot distribution of inference times for both models.\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.boxplot([self.results['pytorch']['times'], self.results['onnx']['times']], \n",
    "                   labels=['PyTorch', 'ONNX'])\n",
    "        plt.title('Model Inference Times Comparison')\n",
    "        plt.ylabel('Time (seconds)')\n",
    "        plt.savefig('inference_times.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def generate_report(self, metrics: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Generate a detailed comparison report.\n",
    "        \n",
    "        Args:\n",
    "            metrics: Dictionary containing metrics for both models\n",
    "        \n",
    "        Returns:\n",
    "            Formatted string containing the comparison report\n",
    "        \"\"\"\n",
    "        report = \"Model Comparison Report\\n\"\n",
    "        report += \"=====================\\n\\n\"\n",
    "        \n",
    "        for model_name in ['pytorch', 'onnx']:\n",
    "            report += f\"{model_name.upper()} Model Metrics:\\n\"\n",
    "            report += f\"{'='*20}\\n\"\n",
    "            report += f\"Accuracy: {metrics[model_name]['accuracy']:.4f}\\n\"\n",
    "            report += f\"Precision: {metrics[model_name]['precision']:.4f}\\n\"\n",
    "            report += f\"Recall: {metrics[model_name]['recall']:.4f}\\n\"\n",
    "            report += f\"F1 Score: {metrics[model_name]['f1']:.4f}\\n\"\n",
    "            report += f\"ROC-AUC Score: {metrics[model_name]['roc_auc']:.4f}\\n\"\n",
    "            report += f\"Average Inference Time: {metrics[model_name]['avg_inference_time']*1000:.2f} ms\\n\"\n",
    "            report += f\"Inference Time Std: {metrics[model_name]['std_inference_time']*1000:.2f} ms\\n\\n\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "def main(df: pd.DataFrame, run_pytorch, run_onnx):\n",
    "    \"\"\"\n",
    "    Main function to run the model comparison.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing 'text' and 'label' columns\n",
    "        run_pytorch: PyTorch model inference function\n",
    "        run_onnx: ONNX model inference function\n",
    "    \"\"\"\n",
    "    # Initialize comparison\n",
    "    comparison = ModelComparison(run_pytorch, run_onnx)\n",
    "    \n",
    "    # Process all texts\n",
    "    comparison.process_batch(df['text'].tolist())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = comparison.calculate_metrics(df['label'].tolist())\n",
    "    \n",
    "    # Generate visualizations\n",
    "    comparison.plot_confusion_matrices(metrics)\n",
    "    comparison.plot_inference_times()\n",
    "    \n",
    "    # Generate and save report\n",
    "    report = comparison.generate_report(metrics)\n",
    "    with open('model_comparison_report.txt', 'w') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    return metrics, report\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(input_test_data, sep='|')\n",
    "    metrics, report = main(df, run_pytorch, run_onnx)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya no quiero continuar en esta vida (depression)\n",
      "'Ya no quiero continuar en esta vida', así dijo ese loro pendejo xD! (non-depression)\n",
      "\n",
      "¿Ser o no ser? (non-depression)\n",
      "¿Ser o no ser? Mejor ya no ser nunca más (depression)\n",
      "\n",
      "Me quiero morir (depression)\n",
      "Me quiero morir, mañana ya es el concierto (non-depression)\n",
      "\n",
      "A veces pienso que la vida no es justa (depression)\n",
      "A veces pienso que la vida no es justa, pero sé que todo mejorará (non-depression)\n",
      "\n",
      "Nada de lo que hago tiene éxito (depression)\n",
      "Nada de lo que hago tiene éxito, pero no me rendiré (non-depression)\n",
      "\n",
      "¿Para qué continuar aquí? (depression)\n",
      "¿Para qué continuar aquí? La fiesta ya murió we (non-depression)\n",
      "\n",
      "Mi vida no tiene sentido (depression)\n",
      "Mi vida no tiene sentido, sin ti amor ven pa ca xD! (non-depression)\n",
      "\n",
      "Soy el mejor (non-depression)\n",
      "Soy el mejor haciendo de mi vida un sin sentido (depression)\n"
     ]
    }
   ],
   "source": [
    "text = 'Ya no quiero continuar en esta vida'\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')\n",
    "\n",
    "text = \"\\'Ya no quiero continuar en esta vida\\', así dijo ese loro pendejo xD!\"\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')\n",
    "\n",
    "print()\n",
    "\n",
    "text = '¿Ser o no ser?'\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')\n",
    "\n",
    "text = \"¿Ser o no ser? Mejor ya no ser nunca más\"\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')\n",
    "\n",
    "print()\n",
    "\n",
    "text = 'Me quiero morir'\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')\n",
    "\n",
    "text = \"Me quiero morir, mañana ya es el concierto\"\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')\n",
    "\n",
    "print()\n",
    "\n",
    "text = 'A veces pienso que la vida no es justa'\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')\n",
    "\n",
    "text = 'A veces pienso que la vida no es justa, pero sé que todo mejorará'\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')\n",
    "\n",
    "print()\n",
    "\n",
    "text = \"Nada de lo que hago tiene éxito\"\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')\n",
    "\n",
    "text = \"Nada de lo que hago tiene éxito, pero no me rendiré\"\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')\n",
    "\n",
    "print()\n",
    "\n",
    "text = \"¿Para qué continuar aquí?\"\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')\n",
    "\n",
    "text = \"¿Para qué continuar aquí? La fiesta ya murió we\"\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')\n",
    "\n",
    "print()\n",
    "\n",
    "text = \"Mi vida no tiene sentido\"\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')\n",
    "\n",
    "text = \"Mi vida no tiene sentido, sin ti amor ven pa ca xD!\"\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "text = \"Soy el mejor\"\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')\n",
    "\n",
    "text = \"Soy el mejor haciendo de mi vida un sin sentido\"\n",
    "input = f\"{{\\\"text\\\": \\\"{text}\\\"}}\"\n",
    "result = run_pytorch(input)\n",
    "print(text,'(depression)' if result['prediction'] == 1 else '(non-depression)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
